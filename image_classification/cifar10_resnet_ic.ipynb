{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T07:41:29.694703Z",
     "start_time": "2022-01-29T07:41:20.544003Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23582,
     "status": "ok",
     "timestamp": 1616326472410,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "zQo6t4NYyCk9",
    "outputId": "c7c7d247-0241-4c51-a2c6-118c5f10cfa0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import os\n",
    "# drive.mount(\"/content/drive\")\n",
    "# os.chdir(\"/content/drive/MyDrive/Libraries\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, Dropout, Concatenate, Add, Dot, Multiply, Reshape, Activation, BatchNormalization, SimpleRNNCell, RNN, SimpleRNN, LSTM, Embedding, Bidirectional, TimeDistributed, Conv1D, Conv2D, MaxPool1D, MaxPool2D, GlobalMaxPool1D, GlobalMaxPool2D, AveragePooling1D, AveragePooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy, CosineSimilarity\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.activations import linear, sigmoid, relu\n",
    "from tensorflow.keras.initializers import RandomNormal, glorot_uniform, he_uniform, Constant\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T07:49:24.663553Z",
     "start_time": "2022-01-29T07:49:24.000154Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1199,
     "status": "ok",
     "timestamp": 1616330163980,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "caoztvC4ORgC",
    "outputId": "960bf7b8-5be5-45e1-803f-263417df4303"
   },
   "outputs": [],
   "source": [
    "(X_tr_val, y_tr_val), (X_te, y_te) = tf.keras.datasets.cifar10.load_data()\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_tr_val, y_tr_val, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T08:51:47.076610Z",
     "start_time": "2022-01-29T08:51:46.607461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 13, 13, 64)   9472        ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 7, 7, 64)    0           ['conv2d_229[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 7, 7, 64)     36928       ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 7, 7, 64)    256         ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_218[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 7, 7, 64)    256         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 7, 7, 64)     4160        ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 7, 7, 64)    256         ['conv2d_232[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TFOpLa  (None, 7, 7, 64)    0           ['activation_219[0][0]',         \n",
      " mbda)                                                            'batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 7, 7, 64)     0           ['tf.__operators__.add_8[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 7, 7, 64)    256         ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 7, 7, 64)     36928       ['activation_221[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 7, 7, 64)    256         ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 7, 7, 64)     4160        ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 7, 7, 64)     0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 7, 7, 64)    256         ['conv2d_235[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TFOpLa  (None, 7, 7, 64)    0           ['activation_222[0][0]',         \n",
      " mbda)                                                            'batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 7, 7, 64)     0           ['tf.__operators__.add_9[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 7, 7, 128)    73856       ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 7, 7, 128)   512         ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 7, 7, 128)    147584      ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 7, 7, 128)   512         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 7, 7, 128)    8320        ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 7, 7, 128)   512         ['conv2d_238[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (TFOpL  (None, 7, 7, 128)   0           ['activation_225[0][0]',         \n",
      " ambda)                                                           'batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 7, 7, 128)    0           ['tf.__operators__.add_10[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 7, 7, 128)    147584      ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 7, 7, 128)   512         ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 7, 7, 128)    147584      ['activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 7, 7, 128)   512         ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 7, 7, 128)    16512       ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 7, 7, 128)   512         ['conv2d_241[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (TFOpL  (None, 7, 7, 128)   0           ['activation_228[0][0]',         \n",
      " ambda)                                                           'batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 7, 7, 128)    0           ['tf.__operators__.add_11[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 7, 7, 256)    295168      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 7, 7, 256)   1024        ['conv2d_242[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 7, 7, 256)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 7, 7, 256)    590080      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 7, 7, 256)   1024        ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 7, 7, 256)    33024       ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 7, 7, 256)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 7, 7, 256)   1024        ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (TFOpL  (None, 7, 7, 256)   0           ['activation_231[0][0]',         \n",
      " ambda)                                                           'batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 7, 7, 256)    0           ['tf.__operators__.add_12[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 7, 7, 256)    590080      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 7, 7, 256)   1024        ['conv2d_245[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 7, 7, 256)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 7, 7, 256)    590080      ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 7, 7, 256)   1024        ['conv2d_246[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 7, 7, 256)    65792       ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 7, 7, 256)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 7, 7, 256)   1024        ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (TFOpL  (None, 7, 7, 256)   0           ['activation_234[0][0]',         \n",
      " ambda)                                                           'batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 7, 7, 256)    0           ['tf.__operators__.add_13[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 7, 7, 512)    1180160     ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 7, 7, 512)   2048        ['conv2d_248[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_236[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 7, 7, 512)   2048        ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 7, 7, 512)    131584      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 7, 7, 512)   2048        ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (TFOpL  (None, 7, 7, 512)   0           ['activation_237[0][0]',         \n",
      " ambda)                                                           'batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 7, 7, 512)    0           ['tf.__operators__.add_14[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 7, 7, 512)   2048        ['conv2d_251[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 7, 7, 512)    2359808     ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 7, 7, 512)   2048        ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 7, 7, 512)    262656      ['activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 7, 7, 512)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 7, 7, 512)   2048        ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (TFOpL  (None, 7, 7, 512)   0           ['activation_240[0][0]',         \n",
      " ambda)                                                           'batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 7, 7, 512)    0           ['tf.__operators__.add_15[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling2d_9 (Gl  (None, 512)         0           ['activation_241[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           5130        ['global_average_pooling2d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,553,162\n",
      "Trainable params: 11,541,642\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 18-layered ResNet\n",
    "def residual_block(x, filters): \n",
    "    z1 = Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    z1 = BatchNormalization()(z1)\n",
    "    z1 = Activation(\"relu\")(z1)\n",
    "    z1 = Conv2D(filters=filters, kernel_size=3, strides=1, padding=\"same\")(z1)\n",
    "    z1 = BatchNormalization()(z1)\n",
    "    z1 = Activation(\"relu\")(z1)\n",
    "\n",
    "    z2 = Conv2D(filters=filters, kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "    z2 = BatchNormalization()(z2)\n",
    "\n",
    "    z = Activation(\"relu\")(z1 + z2)\n",
    "    return z\n",
    "\n",
    "inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "z = Conv2D(filters=64, kernel_size=7, strides=2, padding=\"valid\")(inputs)\n",
    "z = MaxPool2D(pool_size=3, strides=2, padding=\"same\")(z)\n",
    "for _ in range(2):\n",
    "    z = residual_block(z, 64)\n",
    "for _ in range(2):\n",
    "    z = residual_block(z, 128)\n",
    "for _ in range(2):\n",
    "    z = residual_block(z, 256)\n",
    "for _ in range(2):\n",
    "    z = residual_block(z, 512)\n",
    "z = GlobalAveragePooling2D()(z) \n",
    "\n",
    "outputs = Dense(units=10, activation=\"softmax\")(z)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "# # 50-layered ResNet\n",
    "# def residual_block(x, filters): \n",
    "#     z1 = Conv2D(filters=filters[0], kernel_size=1, strides=1, padding=\"same\")(x) \n",
    "#     z1 = BatchNormalization()(z1)\n",
    "#     z1 = Activation(\"relu\")(z1)\n",
    "#     z1 = Conv2D(filters=filters[0], kernel_size=3, strides=1, padding=\"same\")(z1)\n",
    "#     z1 = BatchNormalization()(z1)\n",
    "#     z1 = Activation(\"relu\")(z1)\n",
    "#     z1 = Conv2D(filters=filters[1], kernel_size=1, strides=1, padding=\"same\")(z1)\n",
    "#     z1 = BatchNormalization()(z1)\n",
    "#     z1 = Activation(\"relu\")(z1)\n",
    "\n",
    "#     z2 = Conv2D(filters=filters[1], kernel_size=1, strides=1, padding=\"same\")(x)\n",
    "#     z2 = BatchNormalization()(z2)\n",
    "\n",
    "#     z = Activation(\"relu\")(z1 + z2)\n",
    "#     return z\n",
    "\n",
    "# inputs = Input(shape=(32, 32, 3))\n",
    "\n",
    "# z = Conv2D(filters=64, kernel_size=7, strides=2, padding=\"valid\")(inputs)\n",
    "# z = MaxPool2D(pool_size=3, strides=2, padding=\"same\")(z)\n",
    "# for _ in range(3):\n",
    "#     z = residual_block(z, filters=[64, 256])\n",
    "# for _ in range(4):\n",
    "#     z = residual_block(z, filters=[128, 512])\n",
    "# for _ in range(6):\n",
    "#     z = residual_block(z, filters=[256, 1024])\n",
    "# for _ in range(3):\n",
    "#     z = residual_block(z, filters=[512, 2048])\n",
    "# z = GlobalAveragePooling2D()(z) \n",
    "\n",
    "# outputs = Dense(units=10, activation=\"softmax\")(z)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 420444,
     "status": "ok",
     "timestamp": 1616330688523,
     "user": {
      "displayName": "Jongbeom Kim",
      "photoUrl": "",
      "userId": "17252605958116038360"
     },
     "user_tz": -540
    },
    "id": "LjPbOrNxJHZ6",
    "outputId": "8e379f75-cf01-4ec5-ad49-fad0df17a3b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {white-space: pre-wrap;}\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, 13, 13, 64)   9472        input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 7, 7, 64)     0           conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, 7, 7, 64)     36928       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 7, 7, 64)     256         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 7, 7, 64)     0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, 7, 7, 64)     36928       activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 7, 7, 64)     256         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, 7, 7, 64)     4160        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, 7, 7, 64)     0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 7, 7, 64)     256         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 7, 7, 64)     0           activation_433[0][0]             \n",
      "                                                                 batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, 7, 7, 64)     0           add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, 7, 7, 64)     36928       activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 7, 7, 64)     256         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, 7, 7, 64)     0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, 7, 7, 64)     36928       activation_435[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 7, 7, 64)     256         conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, 7, 7, 64)     4160        activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, 7, 7, 64)     0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 7, 7, 64)     256         conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 7, 7, 64)     0           activation_436[0][0]             \n",
      "                                                                 batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, 7, 7, 64)     0           add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, 7, 7, 128)    73856       activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 7, 7, 128)    512         conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, 7, 7, 128)    0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, 7, 7, 128)    147584      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 7, 7, 128)    512         conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, 7, 7, 128)    8320        activation_437[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, 7, 7, 128)    0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 7, 7, 128)    512         conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 7, 7, 128)    0           activation_439[0][0]             \n",
      "                                                                 batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, 7, 7, 128)    0           add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, 7, 7, 128)    147584      activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 7, 7, 128)    512         conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, 7, 7, 128)    0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, 7, 7, 128)    147584      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 7, 7, 128)    512         conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, 7, 7, 128)    16512       activation_440[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, 7, 7, 128)    0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 7, 7, 128)    512         conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_131 (Add)                   (None, 7, 7, 128)    0           activation_442[0][0]             \n",
      "                                                                 batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, 7, 7, 128)    0           add_131[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, 7, 7, 256)    295168      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 7, 7, 256)    1024        conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, 7, 7, 256)    0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, 7, 7, 256)    590080      activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 7, 7, 256)    1024        conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, 7, 7, 256)    33024       activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, 7, 7, 256)    0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 7, 7, 256)    1024        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_132 (Add)                   (None, 7, 7, 256)    0           activation_445[0][0]             \n",
      "                                                                 batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, 7, 7, 256)    0           add_132[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, 7, 7, 256)    590080      activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 7, 7, 256)    1024        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, 7, 7, 256)    0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, 7, 7, 256)    590080      activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 7, 7, 256)    1024        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, 7, 7, 256)    65792       activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, 7, 7, 256)    0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 7, 7, 256)    1024        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_133 (Add)                   (None, 7, 7, 256)    0           activation_448[0][0]             \n",
      "                                                                 batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, 7, 7, 256)    0           add_133[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, 7, 7, 512)    1180160     activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 7, 7, 512)    2048        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, 7, 7, 512)    0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, 7, 7, 512)    2359808     activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 7, 7, 512)    2048        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, 7, 7, 512)    131584      activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, 7, 7, 512)    0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 7, 7, 512)    2048        conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_134 (Add)                   (None, 7, 7, 512)    0           activation_451[0][0]             \n",
      "                                                                 batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, 7, 7, 512)    0           add_134[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, 7, 7, 512)    2359808     activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 7, 7, 512)    2048        conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, 7, 7, 512)    0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_471 (Conv2D)             (None, 7, 7, 512)    2359808     activation_453[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, 7, 7, 512)    2048        conv2d_471[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_472 (Conv2D)             (None, 7, 7, 512)    262656      activation_452[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, 7, 7, 512)    0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, 7, 7, 512)    2048        conv2d_472[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_135 (Add)                   (None, 7, 7, 512)    0           activation_454[0][0]             \n",
      "                                                                 batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, 7, 7, 512)    0           add_135[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 512)          0           activation_455[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10)           5130        global_average_pooling2d_13[0][0]\n",
      "==================================================================================================\n",
      "Total params: 11,553,162\n",
      "Trainable params: 11,541,642\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 42s 32ms/step - loss: 1.6759 - acc: 0.3810 - val_loss: 2.4161 - val_acc: 0.2674\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.26740, saving model to ResNet18_cifar10.h5\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.1570 - acc: 0.5865 - val_loss: 1.4399 - val_acc: 0.4975\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.26740 to 0.49750, saving model to ResNet18_cifar10.h5\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 41s 32ms/step - loss: 0.9417 - acc: 0.6666 - val_loss: 1.4865 - val_acc: 0.5188\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.49750 to 0.51880, saving model to ResNet18_cifar10.h5\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.7960 - acc: 0.7201 - val_loss: 1.1793 - val_acc: 0.5993\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51880 to 0.59930, saving model to ResNet18_cifar10.h5\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.6530 - acc: 0.7696 - val_loss: 1.0632 - val_acc: 0.6362\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.59930 to 0.63620, saving model to ResNet18_cifar10.h5\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 42s 33ms/step - loss: 0.5391 - acc: 0.8122 - val_loss: 1.0376 - val_acc: 0.6558\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.63620 to 0.65580, saving model to ResNet18_cifar10.h5\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 42s 33ms/step - loss: 0.4387 - acc: 0.8485 - val_loss: 1.2635 - val_acc: 0.6082\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.65580\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.3520 - acc: 0.8802 - val_loss: 1.0003 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.65580 to 0.69310, saving model to ResNet18_cifar10.h5\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.2645 - acc: 0.9129 - val_loss: 1.1382 - val_acc: 0.6727\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.69310\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.2125 - acc: 0.9300 - val_loss: 1.5106 - val_acc: 0.6430\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.69310\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", mode=\"auto\", verbose=1, patience=2)\n",
    "model_path = \"resnet_18_cifar10.h5\"\n",
    "mc = ModelCheckpoint(filepath=model_path, monitor=\"val_acc\", mode=\"auto\", verbose=1, save_best_only=True)\n",
    "gen = ImageDataGenerator(rescale=1/255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "hist = model.fit_generator(data=gen.flow(X_tr, y_tr, batch_size=32), validation_data=(x_val, y_val), epochs=10, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
    "axes[0].plot(hist.history[\"loss\"][1:], label=\"loss\");\n",
    "axes[0].plot(hist.history[\"val_loss\"][1:], label=\"val_loss\");\n",
    "axes[0].legend();\n",
    "\n",
    "axes[1].plot(hist.history[\"acc\"][1:], label=\"acc\");\n",
    "axes[1].plot(hist.history[\"val_acc\"][1:], label=\"val_acc\");\n",
    "axes[1].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-29T08:52:34.171191Z",
     "start_time": "2022-01-29T08:52:34.158152Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1737,
     "status": "ok",
     "timestamp": 1610808695038,
     "user": {
      "displayName": "modric e",
      "photoUrl": "",
      "userId": "13359243005730783631"
     },
     "user_tz": -540
    },
    "id": "JtAMi8mS43Xx",
    "outputId": "48f1b434-69c7-4542-e9bf-8b44d1944150"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history[\"accuracy\"]\n",
    "# val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "# loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# epochs_range = range(10)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
    "# plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
    "# plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_cifar10.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
